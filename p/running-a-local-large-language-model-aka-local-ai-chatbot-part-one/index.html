<!DOCTYPE html>
<html lang="en-us"><head>
    <link rel="icon" type="image/png" href="/favicon/favicon.png">
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='This is blog post details my journey in setting up and running an (LLM) large-language-model on my very own computer in order to have my own alternative to ChatGPT'><title>Running a Local Large Language Model (AKA Local AI ChatBot) PART ONE</title>

    <link rel='canonical' href='https://arjdroid.me/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/'>

<link rel="stylesheet" href="/scss/style.min.css">
<meta property='og:title' content='Running a Local Large Language Model (AKA Local AI ChatBot) PART ONE'>
<meta property='og:description' content='This is blog post details my journey in setting up and running an (LLM) large-language-model on my very own computer in order to have my own alternative to ChatGPT'>
<meta property='og:url' content='https://arjdroid.me/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/'>
<meta property='og:site_name' content='The Droid Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='ai' /><meta property='article:tag' content='llm' /><meta property='article:tag' content='gpt' /><meta property='article:published_time' content='2024-01-11T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2024-01-11T00:00:00&#43;00:00'/><meta property='og:image' content='https://arjdroid.me/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac.png' />
<meta name="twitter:title" content="Running a Local Large Language Model (AKA Local AI ChatBot) PART ONE">
<meta name="twitter:description" content="This is blog post details my journey in setting up and running an (LLM) large-language-model on my very own computer in order to have my own alternative to ChatGPT"><meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:image" content='https://arjdroid.me/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac.png' /></head>
<body class="">
        <div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar">
            <aside class="sidebar left-sidebar sticky">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header class="site-info">
        
            <figure class="site-avatar">
                

                
                    
                    <img src="/img/avatar_hu99862c33b9e1069572ca594846bf10a3_832614_300x300_resize_q75_box.jpg" width="300"
                        height="300" class="site-logo" loading="lazy" alt="Avatar">
                

                <span class="emoji">üñ•Ô∏è</span>
            </figure>
        
        <h1 class="site-name"><a href="https://arjdroid.me">The Droid Blog</a></h1>
        <h2 class="site-description">Computer Wizard In Training</h2>
    </header>

    <ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='https://arjdroid.me/'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='https://arjdroid.me/about'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='https://arjdroid.me/p/rss'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="5" cy="19" r="1" />
  <path d="M4 4a16 16 0 0 1 16 16" />
  <path d="M4 11a9 9 0 0 1 9 9" />
</svg>



                
                <span>RSS</span>
            </a>
        </li>
        
    </ol>
</aside>
            <main class="main full-width">
    <div id="article-toolbar">
        <a href="https://arjdroid.me" class="back-home">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



            <span>Back</span>
        </a>
    </div>

    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <img srcset="/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac_hua887970ac5a2db07a2e0e5d5b313dc62_398330_1024x0_resize_box_3.png 1024w, /p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac_hua887970ac5a2db07a2e0e5d5b313dc62_398330_2000x0_resize_box_3.png 2000w"
                    src="/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac_hua887970ac5a2db07a2e0e5d5b313dc62_398330_2000x0_resize_box_3.png" width="1410" height="831" loading="lazy"
                    alt="Featured image of post Running a Local Large Language Model (AKA Local AI ChatBot) PART ONE" />
            
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="https://arjdroid.me/categories/ai/" 
                    class="color-tag"
                    data-image="/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac_hua887970ac5a2db07a2e0e5d5b313dc62_398330_20x20_fill_box_smart1_3.png" 
                    data-key="" 
                    data-hash="md5-ngUdSI9rXd3eSdwvxQNKhQ==">
                    ai
                </a>
            
        
            <a href="https://arjdroid.me/categories/technical/" 
                    class="color-tag"
                    data-image="/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/llama2-on-mac_hua887970ac5a2db07a2e0e5d5b313dc62_398330_20x20_fill_box_smart1_3.png" 
                    data-key="" 
                    data-hash="md5-ngUdSI9rXd3eSdwvxQNKhQ==">
                    technical
                </a>
            
        
    </header>
    

    <h2 class="article-title">
        <a href="https://arjdroid.me/p/running-a-local-large-language-model-aka-local-ai-chatbot-part-one/">Running a Local Large Language Model (AKA Local AI ChatBot) PART ONE</a>
    </h2>

    
    <h3 class="article-subtitle">
        This is blog post details my journey in setting up and running an (LLM) large-language-model on my very own computer in order to have my own alternative to ChatGPT
    </h3>
    <footer class="article-time">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <time class="article-time--published">Jan 11, 2024</time>
    </footer></div>
</header>

    <section class="article-content">
    <h2 id="introduction">Introduction</h2>
<p>I&rsquo;m sure that over the past year you&rsquo;ve heard a <em>LOT</em> about AI, ChatGPT, and maybe something called a Large Language Model.</p>
<p>Well, the underlying technique with which we&rsquo;ve had a lot of recent advances in AI, resulting in the offerring of such powerful tools like <a class="link" href="https://chat.openai.com"  target="_blank" rel="noopener"
    >ChatGPT</a>, <a class="link" href="https://perplexity.ai"  target="_blank" rel="noopener"
    >Perplexity</a>, etc. has been the Large Language Model.</p>
<p>If you&rsquo;re really curious, and have the time (~1 hour) to really get down to some details about how these models work and how we use them, I <em>highly</em> recommend you watch this <a class="link" href="https://youtu.be/zjkBMFhNj_g?si=AHkn0iOyrgwREBNK"  target="_blank" rel="noopener"
    >YouTube Video</a></p>
<p>Additionally, you can also watch the Royal Institute&rsquo;s <a class="link" href="https://www.youtube.com/watch?v=b76gsOSkHB4"  target="_blank" rel="noopener"
    >video</a> which is more of a general opener rather than very many technical details.</p>
<p>However, in today&rsquo;s blog post we&rsquo;re just jumping straight into how we can get started actually running some models on our very own systems!</p>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>A computer running either Linux or macOS (Windows users have other options not covered in this Blog Post)</li>
<li>Decent hardware (It says at least 8GB RAM to run the smallest models), but you can also expand by having more RAM, faster CPUs and a discreteGPU
<ul>
<li>In this post I&rsquo;m demonstrating it on an M1 MacBook Air, so anything in that ballpark or faster should be good to run the most basic stuff.</li>
</ul>
</li>
<li>A lot of storage available, at least 50GB to be comfortable</li>
</ul>
<blockquote>
<p>For this demonstration, I am showing <code>ollama</code> running on an Apple M1 MacBook Air with an 8 core CPU, 8 core GPU, 16GB RAM and 512GB of Storage.</p>
<p>I have also tested <code>ollama</code> running on a Fedora Linux system with 16GB RAM, an AMD Ryzen 7 3700X, and an Nvidia GeForce RTX 3070 with 8 GB VRAM. Future blog posts will be on this system.</p>
</blockquote>
<h2 id="starting-off">Starting Off</h2>
<p>For this project I&rsquo;m going to be using the <a class="link" href="https://ollama.ai"  target="_blank" rel="noopener"
    >ollama</a> tool. It makes the whole thing <em>very</em> simple, because it&rsquo;s almost plug and play, while still allowing you to have a lot of control and customisation.</p>
<p>It supports GPU acceleration (if you have it), running a local API (so that you can use the model with a GUI interface instead of the command line), etc.</p>
<p>And the best thing? It&rsquo;s completely open source!</p>
<h3 id="installation">Installation</h3>
<p>You can go to the ollama website <a class="link" href="https://ollamai.ai"  target="_blank" rel="noopener"
    >https://ollamai.ai</a> or their GitHub <a class="link" href="https://github.com/jmorganca/ollama"  target="_blank" rel="noopener"
    >https://github.com/jmorganca/ollama</a></p>
<p>And follow the basic instructions from there</p>
<p>On a Mac, it&rsquo;s quite simple as you just need to install their Application file (which has been Apple Notarised so there&rsquo;s less worry about sketchy software too) and then you have access to the <code>ollama</code> command in your terminal.</p>
<blockquote>
<p>Note: you do have to trust the application and give it administrator / root access</p>
</blockquote>
<p>Once you&rsquo;ve done that, you&rsquo;re ready to go!</p>
<p>They recommend you start off with the base, 7 billion parameter <code>llama2</code> model and you can do that with:</p>
<p><code>ollama run llama2</code></p>
<p>And there you have it! You can talk to it, ask it questions, even write some code.</p>
<p>However, once you eventually get bored with that, you should start looking at other models, with different purposes.</p>
<p>I&rsquo;d suggest taking a look at <code>mistral</code> as it&rsquo;s similarly lightweight and quite responsive, as well as <em>so many more!</em></p>
<p>You can check out the <a class="link" href="https://ollama.ai/library"  target="_blank" rel="noopener"
    >ollama library</a> to see all sorts of different options. But remember, larger models require more RAM and or more VRAM to run.</p>
<h3 id="tidbits">Tidbits</h3>
<p>I pasted all the above contents of the blog post into the llama2 model and asked it to conclude the post, here&rsquo;s what it said:</p>
<p>Running a local LLM can offer several advantages, such as faster response times, greater
control over the model&rsquo;s training data, and reduced latency compared to using cloud-based
models. By running our own LLMs, we can also explore new use cases and applications that are
not yet possible with existing models.</p>
<p>Pretty good!</p>
<h2 id="up-next">Up Next</h2>
<p>Right now, I&rsquo;m on a delivery of new RAM modules to upgrade my PC so that I can run larger models like <code>mixtral</code> and <code>llama2:70b</code> as they promise to be a lot more powerful.</p>
<p>Upcoming blog posts in this series will detail the differences between these kinds of models, as well as some more exploration like setting up a nice web ui to interface with them more comfortably and from more devices on the network!</p>
<p>I also want to learn about different kinds of tests they use to evaluate the performance of these models and run them myself to compare the results.</p>
<blockquote>
<blockquote>
<p>See you next time</p>
</blockquote>
</blockquote>
<hr>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="https://arjdroid.me/tags/ai/">ai</a>
        
            <a href="https://arjdroid.me/tags/llm/">llm</a>
        
            <a href="https://arjdroid.me/tags/gpt/">gpt</a>
        
    </section>


    </footer>

    
</article>

    <aside class="related-contents--wrapper">
    
    
</aside>

    
        
    

    <footer class="site-footer">
    <section class="copyright">&copy; 2024 The Droid Blog</section>
    <section class="powerby">
        Built with <b><a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a></b> with the <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener">Stack Theme by Jimmy Cai</a></b> and hosted with <b><a href="https://github.com" target="_blank" rel="noopener">Github Pages</a></b><br />
        This Website is Open Source! Source Code <b><a href="https://github.com/Arjdroid/the_droid_blog-source_files">Here</a></b>
    </section>
</footer>

<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true" style="display:none">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
            </main>
        </div>
        
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<link rel="stylesheet" href="/css/highlight/light.min.css" media="(prefers-color-scheme: light)">
<link rel="stylesheet" href="/css/highlight/dark.min.css" media="(prefers-color-scheme: dark)">


    </body>
</html>
